{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa97bf4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128657bb",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea3f30",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64038d2a",
   "metadata": {},
   "source": [
    "**Import Packages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c66c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats.stats as stats\n",
    "import pandas.core.algorithms as algos\n",
    "from sklearn import preprocessing, model_selection\n",
    "from library.sb_utils import save_file\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e421480",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3eba74",
   "metadata": {},
   "source": [
    "**Read Data Into Pandas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7452cff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10506 entries, 0 to 10505\n",
      "Columns: 224 entries, Species to IsDayAfterSpray\n",
      "dtypes: float64(185), int64(34), object(5)\n",
      "memory usage: 18.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#read data into pandas\n",
    "filepath = '../data/data_cleaned.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412cef55",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52804f3a",
   "metadata": {},
   "source": [
    "**Set Random Seed:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ae733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed for repeatability\n",
    "random_seed = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1506af",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edccf8cb",
   "metadata": {},
   "source": [
    "**Column Definitions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe91586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the categorical and continuous variables\n",
    "categorical_columns = ['Species','IsDowntownCore','IsNorthWestZone','IsNorthEastZone','TrapZone','IsInSeason','Month',\n",
    "           'Week', 'IsPeakSeason', 'IsSprayed', 'IsOptimalTemp','PrecipConditions','PrecipWeekly_Score',\n",
    "           'MoistureConditions','WindConditions','InSprayBounds', 'IsDayAfterSpray','IsNearSprayZone','IsRecentlySprayed',\n",
    "           'WeatherCode_BR','WeatherCode_DZ','WeatherCode_HZ','WeatherCode_NONE','WeatherCode_RA','WeatherCode_TS',\n",
    "           'WeatherCode_TSRA']\n",
    "\n",
    "continuous_columns = ['PrecipWeekly', 'Tavg', 'Tmax','Tmin','Tdepart','Tdew_point','Twet_bulb','HeatDegDay','CoolDegDay', \n",
    "           'PrecipTotal','NumMosquitos', 'DaysSincePrecip', 'DaylightMinutes', 'RelHumidity', 'Wind_AvgSpeed', \n",
    "           'Lat_Long_Product', 'StnPressure', 'TrapSprayDistance', 'DaysSinceSpray','Prev_Check','Tavg_7days', \n",
    "           'Tavg_14days', 'Tavg_21days', 'Tavg_28days','Wind_AvgSpeed_7days','Wind_AvgSpeed_14days','Wind_AvgSpeed_21days', 'Wind_AvgSpeed_28days',\n",
    "           'PrecipTotal_7days', 'PrecipTotal_14days', 'PrecipTotal_21days', 'PrecipTotal_28days', 'RelHumidity_7days', \n",
    "           'RelHumidity_14days','RelHumidity_21days', 'RelHumidity_28days', 'Tavg_lag1', 'Tavg_lag2', 'Tavg_lag3',\n",
    "           'Tavg_lag4', 'Tavg_lag5', 'Tavg_lag6', 'Tavg_lag7','Tavg_lag8', 'Tavg_lag9', 'Tavg_lag10', 'Tavg_lag11',\n",
    "           'Tavg_lag12', 'Tavg_lag13', 'Tavg_lag14', 'Tavg_lag15', 'Tavg_lag16', 'Tavg_lag17', 'Tavg_lag18',\n",
    "           'Tavg_lag19', 'Tavg_lag20', 'Tavg_lag21', 'Tavg_lag22', 'Tavg_lag23', 'Tavg_lag24', 'Tavg_lag25',\n",
    "           'Tavg_lag26', 'Tavg_lag27', 'Tavg_lag28', 'Wind_AvgSpeed_lag1', 'Wind_AvgSpeed_lag2', 'Wind_AvgSpeed_lag3',\n",
    "           'Wind_AvgSpeed_lag4', 'Wind_AvgSpeed_lag5', 'Wind_AvgSpeed_lag6', 'Wind_AvgSpeed_lag7', 'Wind_AvgSpeed_lag8',\n",
    "           'Wind_AvgSpeed_lag9', 'Wind_AvgSpeed_lag10', 'Wind_AvgSpeed_lag11', 'Wind_AvgSpeed_lag12','Wind_AvgSpeed_lag13',\n",
    "           'Wind_AvgSpeed_lag14', 'Wind_AvgSpeed_lag15', 'Wind_AvgSpeed_lag16', 'Wind_AvgSpeed_lag17',\n",
    "           'Wind_AvgSpeed_lag18', 'Wind_AvgSpeed_lag19', 'Wind_AvgSpeed_lag20', 'Wind_AvgSpeed_lag21',\n",
    "           'Wind_AvgSpeed_lag22', 'Wind_AvgSpeed_lag23', 'Wind_AvgSpeed_lag24', 'Wind_AvgSpeed_lag25',\n",
    "           'Wind_AvgSpeed_lag26', 'Wind_AvgSpeed_lag27', 'Wind_AvgSpeed_lag28', 'PrecipTotal_lag1', 'PrecipTotal_lag2',\n",
    "           'PrecipTotal_lag3', 'PrecipTotal_lag4', 'PrecipTotal_lag5', 'PrecipTotal_lag6', 'PrecipTotal_lag7',\n",
    "           'PrecipTotal_lag8', 'PrecipTotal_lag9', 'PrecipTotal_lag10', 'PrecipTotal_lag11', 'PrecipTotal_lag12',\n",
    "           'PrecipTotal_lag13', 'PrecipTotal_lag14', 'PrecipTotal_lag15', 'PrecipTotal_lag16', 'PrecipTotal_lag17',\n",
    "           'PrecipTotal_lag18', 'PrecipTotal_lag19', 'PrecipTotal_lag20', 'PrecipTotal_lag21', 'PrecipTotal_lag22',\n",
    "           'PrecipTotal_lag23', 'PrecipTotal_lag24', 'PrecipTotal_lag25', 'PrecipTotal_lag26', 'PrecipTotal_lag27',\n",
    "           'PrecipTotal_lag28', 'DaylightMinutes_lag1', 'DaylightMinutes_lag2', 'DaylightMinutes_lag3',\n",
    "           'DaylightMinutes_lag4', 'DaylightMinutes_lag5', 'DaylightMinutes_lag6', 'DaylightMinutes_lag7',\n",
    "           'DaylightMinutes_lag8', 'DaylightMinutes_lag9', 'DaylightMinutes_lag10', 'DaylightMinutes_lag11',\n",
    "           'DaylightMinutes_lag12', 'DaylightMinutes_lag13', 'DaylightMinutes_lag14', 'DaylightMinutes_lag15',\n",
    "           'DaylightMinutes_lag16', 'DaylightMinutes_lag17', 'DaylightMinutes_lag18', 'DaylightMinutes_lag19',\n",
    "           'DaylightMinutes_lag20', 'DaylightMinutes_lag21', 'DaylightMinutes_lag22', 'DaylightMinutes_lag23',\n",
    "           'DaylightMinutes_lag24', 'DaylightMinutes_lag25', 'DaylightMinutes_lag26', 'DaylightMinutes_lag27',\n",
    "           'DaylightMinutes_lag28', 'RelHumidity_lag1', 'RelHumidity_lag2', 'RelHumidity_lag3', 'RelHumidity_lag4',\n",
    "           'RelHumidity_lag5', 'RelHumidity_lag6', 'RelHumidity_lag7', 'RelHumidity_lag8', 'RelHumidity_lag9',\n",
    "           'RelHumidity_lag10', 'RelHumidity_lag11', 'RelHumidity_lag12', 'RelHumidity_lag13', 'RelHumidity_lag14',\n",
    "           'RelHumidity_lag15', 'RelHumidity_lag16', 'RelHumidity_lag17', 'RelHumidity_lag18', 'RelHumidity_lag19',\n",
    "           'RelHumidity_lag20', 'RelHumidity_lag21', 'RelHumidity_lag22', 'RelHumidity_lag23', 'RelHumidity_lag24',\n",
    "           'RelHumidity_lag25', 'RelHumidity_lag26', 'RelHumidity_lag27', 'RelHumidity_lag28', 'Tavg_lag7_mean',\n",
    "           'Tavg_lag14_mean', 'Tavg_lag21_mean', 'Tavg_lag28_mean', 'Wind_AvgSpeed_lag7_mean', 'Wind_AvgSpeed_lag14_mean',\n",
    "           'Wind_AvgSpeed_lag21_mean', 'Wind_AvgSpeed_lag28_mean', 'PrecipTotal_lag7_mean', 'PrecipTotal_lag14_mean',\n",
    "           'PrecipTotal_lag21_mean', 'PrecipTotal_lag28_mean', 'DaylightMinutes_lag7_mean', 'DaylightMinutes_lag14_mean',\n",
    "           'DaylightMinutes_lag21_mean', 'DaylightMinutes_lag28_mean', 'RelHumidity_lag7_mean', 'RelHumidity_lag14_mean',\n",
    "           'RelHumidity_lag21_mean', 'RelHumidity_lag28_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eea214",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479c068",
   "metadata": {},
   "source": [
    "## 3.1 Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d8586",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f306fbb",
   "metadata": {},
   "source": [
    "**Separate Input Features (X) From Target Feature (y):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c60b7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the data into feature matrix (X) and target vector (y)\n",
    "X = df.drop(columns='WnvPresent')\n",
    "y = df['WnvPresent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf88b27",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c79b67a",
   "metadata": {},
   "source": [
    "**Split Data Into Train (70%) and Test Sets (30%):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d68b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y, train_size=0.7, stratify=y, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c91056",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb2513",
   "metadata": {},
   "source": [
    "## 3.2 Weight of Evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94212e7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287a6bb",
   "metadata": {},
   "source": [
    "**Functions For Calculating Weight of Evidence:**\n",
    "* Get bins for continuous variables \n",
    "* Get bins for discrete variables\n",
    "* Get the weight of evidence table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff7479bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the bins for continuous variables\n",
    "def continuous_bins(X,y,max_bins=20,min_bins=2):\n",
    "    spearman_r = 0\n",
    "    n = max_bins\n",
    "    \n",
    "    #create the bins\n",
    "    while np.abs(spearman_r) < 1:\n",
    "        \n",
    "        #if below minimum bins manually create bins\n",
    "        if n < min_bins + 1:\n",
    "            bins = algos.quantile(X, np.linspace(0, 1, min_bins + 1))\n",
    "            if len(np.unique(bins)) == 2:\n",
    "                bins = np.insert(bins,0,1)\n",
    "                bins[1] = bins[1]-(bins[1]/2)\n",
    "            df_bins = pd.DataFrame({'X':X, 'y':y, \"Bin\": pd.cut(X, np.unique(bins),include_lowest=True)}) \\\n",
    "                .groupby('Bin')\n",
    "            break\n",
    "        \n",
    "        #create bins and check Spearman correlation\n",
    "        df_bins = pd.DataFrame({'X':X,'y':y,'Bin':pd.qcut(X,n,duplicates='drop')}).groupby('Bin')\n",
    "        spearman_r, p_val = stats.spearmanr(df_bins['X'].mean(),df_bins['y'].mean())\n",
    "        n -= 1\n",
    "\n",
    "    return df_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad0a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the bins for discrete variables\n",
    "def discrete_bins(X,y):\n",
    "    return pd.DataFrame({'X':X, 'y':y}).groupby('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e928a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the weight of evidence table\n",
    "def get_woe_table(df_bins, is_continuous, feature_name):\n",
    "    \n",
    "    #for continuous data\n",
    "    if is_continuous:\n",
    "        min_value = df_bins['X'].min()\n",
    "        max_value = df_bins['X'].max()\n",
    "    \n",
    "    #for discrete data\n",
    "    else:\n",
    "        min_value = df_bins['y'].count().index\n",
    "        max_value = min_value\n",
    "\n",
    "        \n",
    "    count_total = df_bins['y'].count()\n",
    "    count_positive = df_bins['y'].sum()\n",
    "    count_negative = count_total - count_positive\n",
    "        \n",
    "    df_woe_table =  pd.DataFrame({\n",
    "        'Feature':feature_name,\n",
    "        'Minimum':min_value,\n",
    "        'Maximum':max_value,\n",
    "        'Total':count_total,\n",
    "        'TotalPositive':count_positive,\n",
    "        'TotalNegative':count_negative,\n",
    "        'PositiveRate': count_positive/count_total,\n",
    "        'NegativeRate': count_negative/count_total,\n",
    "        'ProportionOfPositives': count_positive / count_positive.sum(),\n",
    "        'ProportionOfNegatives': count_negative / count_negative.sum(),\n",
    "    })\n",
    "    \n",
    "    df_woe_table['WOE'] = np.log(df_woe_table['ProportionOfPositives']/df_woe_table['ProportionOfNegatives'])\n",
    "    df_woe_table['IV'] = (df_woe_table['ProportionOfPositives'] - df_woe_table['ProportionOfNegatives']) \\\n",
    "        * df_woe_table['WOE']\n",
    "    \n",
    "    #handle infinity values\n",
    "    df_woe_table = df_woe_table.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    #drop any rows where there were no values in the bin\n",
    "    df_woe_table = df_woe_table.drop(index = df_woe_table[df_woe_table['Total'] == 0].index)\n",
    "    \n",
    "    return df_woe_table.reset_index(drop=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d83b488",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8baa99",
   "metadata": {},
   "source": [
    "**Weight of Evidence and Information Value For Each Feature:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7e2ba18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#get WOE and IV values for each feature in X_train\n",
    "df_woe = None\n",
    "for column in categorical_columns:\n",
    "    \n",
    "    df_bins = discrete_bins(X_train[column],y_train)\n",
    "    woe_table = get_woe_table(df_bins, False, column)\n",
    "    \n",
    "    if df_woe is None:\n",
    "        df_woe = woe_table\n",
    "    else:\n",
    "        df_woe = pd.concat([df_woe,woe_table])\n",
    "        \n",
    "for column in continuous_columns:\n",
    "    \n",
    "    df_bins = continuous_bins(X_train[column],y_train)\n",
    "    woe_table = get_woe_table(df_bins, True, column)\n",
    "    \n",
    "    if df_woe is None:\n",
    "        df_woe = woe_table\n",
    "    else:\n",
    "        df_woe = pd.concat([df_woe,woe_table])\n",
    " \n",
    "\n",
    "df_woe = df_woe.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09fdda",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b96e08",
   "metadata": {},
   "source": [
    "**Maximum Information Value For Each Feature:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6fbce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the max IV for each feature\n",
    "df_woe = df_woe.groupby('Feature')['IV'].max().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf4cb5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9093a59",
   "metadata": {},
   "source": [
    "**Keep Features With Information Value Between 0.05 and 0.8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79af55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features with IV >= 0.05 and IV <= 0.8\n",
    "features = df_woe[(df_woe['IV'] >= 0.05) & \\\n",
    "                  (df_woe['IV'] <= 0.8)].sort_values(by='IV', ascending=False)['Feature'].tolist()\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa3d6b0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38416020",
   "metadata": {},
   "source": [
    "**Update the Feature Lists:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd131b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the feature lists\n",
    "categorical_columns = list(set(categorical_columns) & set(X_train.columns))\n",
    "continuous_columns = list(set(continuous_columns) & set(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0349bdc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944637e9",
   "metadata": {},
   "source": [
    "## 3.3 Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68518e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the encoder to the training data\n",
    "encoder = preprocessing.OneHotEncoder(sparse=False, drop='first')\n",
    "encoder.fit(X_train[categorical_columns])\n",
    "\n",
    "#Transform the training data\n",
    "encoded_columns = pd.DataFrame(encoder.transform(X_train[categorical_columns]))\n",
    "encoded_columns.columns = encoder.get_feature_names(categorical_columns)\n",
    "encoded_columns.index = X_train.index\n",
    "X_train =  pd.concat([X_train,encoded_columns], axis=1).drop(columns=categorical_columns)\n",
    "\n",
    "new_categorical_columns = encoded_columns.columns\n",
    "\n",
    "\n",
    "#Transform the test data\n",
    "encoded_columns = pd.DataFrame(encoder.transform(X_test[categorical_columns]))\n",
    "encoded_columns.columns = encoder.get_feature_names(categorical_columns)\n",
    "encoded_columns.index = X_test.index\n",
    "X_test = pd.concat([X_test,encoded_columns], axis=1).drop(columns=categorical_columns)\n",
    "\n",
    "\n",
    "#update the column list\n",
    "categorical_columns = new_categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619387ae",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee846a",
   "metadata": {},
   "source": [
    "## 3.4 Scale Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03b253b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Numerical Data\n",
    "\n",
    "#Fit the scaler to the training data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train[continuous_columns])\n",
    "\n",
    "#Transform the training data\n",
    "scaled = pd.DataFrame(scaler.transform(X_train[continuous_columns]))\n",
    "scaled.columns = continuous_columns\n",
    "scaled.index = X_train.index\n",
    "X_train = pd.concat([scaled, X_train.drop(columns=continuous_columns)], axis=1)\n",
    "\n",
    "#Transform the test data\n",
    "scaled = pd.DataFrame(scaler.transform(X_test[continuous_columns]))\n",
    "scaled.columns = continuous_columns\n",
    "scaled.index = X_test.index\n",
    "X_test = pd.concat([scaled, X_test.drop(columns=continuous_columns)], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd8bfb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff02b59",
   "metadata": {},
   "source": [
    "## 3.5 Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da897c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe406a",
   "metadata": {},
   "source": [
    "**Remove the Feature With the Greatest VIF Until All Features Have VIF < 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9949c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "#remove features until VIF among all features is < 2\n",
    "\n",
    "X_train = X_train.sort_index(axis=1)\n",
    "X_test = X_test.sort_index(axis=1)\n",
    "\n",
    "while len(X_train.columns) > 0:\n",
    "\n",
    "    df_VIF = pd.DataFrame({'Feature':X_train.columns})\n",
    "    df_VIF['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(len(X_train.columns))]\n",
    "    \n",
    "    if df_VIF.loc[df_VIF['VIF'].idxmax()]['VIF'] < 2:\n",
    "        break\n",
    "        \n",
    "    X_train = X_train.drop(columns=df_VIF.loc[df_VIF['VIF'].idxmax()]['Feature'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99839222",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32cf5ca",
   "metadata": {},
   "source": [
    "**Remove the Same Columns From the Test Set:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a70b45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the same columns from the test data\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fe352",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6397e",
   "metadata": {},
   "source": [
    "## 3.6 Save The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb78e4f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b1232f",
   "metadata": {},
   "source": [
    "**Save Input Features (Training Set):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "098f63b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"../data\\X_train.csv\"\n"
     ]
    }
   ],
   "source": [
    "#Save X_train\n",
    "datapath = '../data'\n",
    "save_file(X_train, 'X_train.csv', datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41858b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0c67c",
   "metadata": {},
   "source": [
    "**Save Target Feature (Training Set):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f63e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"../data\\y_train.csv\"\n"
     ]
    }
   ],
   "source": [
    "#Save y_train\n",
    "datapath = '../data'\n",
    "save_file(y_train, 'y_train.csv', datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09fe0c8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283ca250",
   "metadata": {},
   "source": [
    "**Save Input Features (Test Set):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5fb6ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"../data\\X_test.csv\"\n"
     ]
    }
   ],
   "source": [
    "#Save X_test\n",
    "datapath = '../data'\n",
    "save_file(X_test, 'X_test.csv', datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c60263",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e30b71",
   "metadata": {},
   "source": [
    "**Save Target Feature (Test Set):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6192ed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file already exists with this name.\n",
      "\n",
      "Do you want to overwrite? (Y/N)y\n",
      "Writing file.  \"../data\\y_test.csv\"\n"
     ]
    }
   ],
   "source": [
    "#Save y_test\n",
    "datapath = '../data'\n",
    "save_file(y_test, 'y_test.csv', datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c46396",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
