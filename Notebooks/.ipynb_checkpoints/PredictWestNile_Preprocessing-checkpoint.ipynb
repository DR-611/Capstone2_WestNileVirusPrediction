{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c66c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats.stats as stats\n",
    "import pandas.core.algorithms as algos\n",
    "from sklearn import preprocessing, model_selection\n",
    "from library.sb_utils import save_file\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7452cff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10506 entries, 0 to 10505\n",
      "Columns: 222 entries, Species to Prev_Check\n",
      "dtypes: float64(184), int64(33), object(5)\n",
      "memory usage: 17.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#read trap data into pandas\n",
    "filepath = '../data/data_cleaned.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ae733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed for repeatability\n",
    "random_seed = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe91586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the categorical and continuous variables\n",
    "categorical_columns = ['Species','IsDowntownCore','IsNorthWestZone','IsNorthEastZone','TrapZone','IsInSeason','Month',\n",
    "           'Week', 'IsPeakSeason', 'IsSprayed', 'IsOptimalTemp','PrecipConditions','PrecipWeekly_Score',\n",
    "           'MoistureConditions','WindConditions','InSprayBounds', 'IsDayAfterSpray','IsNearSprayZone','IsRecentlySprayed',\n",
    "           'WeatherCode_BR','WeatherCode_DZ','WeatherCode_HZ','WeatherCode_NONE','WeatherCode_RA','WeatherCode_TS',\n",
    "           'WeatherCode_TSRA']\n",
    "\n",
    "continuous_columns = ['PrecipWeekly', 'Tavg', 'Tmax','Tmin','Tdepart','Tdew_point','Twet_bulb','HeatDegDay','CoolDegDay', \n",
    "           'PrecipTotal','NumMosquitos', 'DaysSincePrecip', 'DaylightMinutes', 'RelHumidity', 'Wind_AvgSpeed',  \n",
    "           'StnPressure', 'TrapSprayDistance', 'DaysSinceSpray','Prev_Check','Tavg_7days', 'Tavg_14days', 'Tavg_21days', \n",
    "           'Tavg_28days','Wind_AvgSpeed_7days','Wind_AvgSpeed_14days','Wind_AvgSpeed_21days', 'Wind_AvgSpeed_28days',\n",
    "           'PrecipTotal_7days', 'PrecipTotal_14days', 'PrecipTotal_21days', 'PrecipTotal_28days', 'RelHumidity_7days', \n",
    "           'RelHumidity_14days','RelHumidity_21days', 'RelHumidity_28days', 'Tavg_lag1', 'Tavg_lag2', 'Tavg_lag3',\n",
    "           'Tavg_lag4', 'Tavg_lag5', 'Tavg_lag6', 'Tavg_lag7','Tavg_lag8', 'Tavg_lag9', 'Tavg_lag10', 'Tavg_lag11',\n",
    "           'Tavg_lag12', 'Tavg_lag13', 'Tavg_lag14', 'Tavg_lag15', 'Tavg_lag16', 'Tavg_lag17', 'Tavg_lag18',\n",
    "           'Tavg_lag19', 'Tavg_lag20', 'Tavg_lag21', 'Tavg_lag22', 'Tavg_lag23', 'Tavg_lag24', 'Tavg_lag25',\n",
    "           'Tavg_lag26', 'Tavg_lag27', 'Tavg_lag28', 'Wind_AvgSpeed_lag1', 'Wind_AvgSpeed_lag2', 'Wind_AvgSpeed_lag3',\n",
    "           'Wind_AvgSpeed_lag4', 'Wind_AvgSpeed_lag5', 'Wind_AvgSpeed_lag6', 'Wind_AvgSpeed_lag7', 'Wind_AvgSpeed_lag8',\n",
    "           'Wind_AvgSpeed_lag9', 'Wind_AvgSpeed_lag10', 'Wind_AvgSpeed_lag11', 'Wind_AvgSpeed_lag12','Wind_AvgSpeed_lag13',\n",
    "           'Wind_AvgSpeed_lag14', 'Wind_AvgSpeed_lag15', 'Wind_AvgSpeed_lag16', 'Wind_AvgSpeed_lag17',\n",
    "           'Wind_AvgSpeed_lag18', 'Wind_AvgSpeed_lag19', 'Wind_AvgSpeed_lag20', 'Wind_AvgSpeed_lag21',\n",
    "           'Wind_AvgSpeed_lag22', 'Wind_AvgSpeed_lag23', 'Wind_AvgSpeed_lag24', 'Wind_AvgSpeed_lag25',\n",
    "           'Wind_AvgSpeed_lag26', 'Wind_AvgSpeed_lag27', 'Wind_AvgSpeed_lag28', 'PrecipTotal_lag1', 'PrecipTotal_lag2',\n",
    "           'PrecipTotal_lag3', 'PrecipTotal_lag4', 'PrecipTotal_lag5', 'PrecipTotal_lag6', 'PrecipTotal_lag7',\n",
    "           'PrecipTotal_lag8', 'PrecipTotal_lag9', 'PrecipTotal_lag10', 'PrecipTotal_lag11', 'PrecipTotal_lag12',\n",
    "           'PrecipTotal_lag13', 'PrecipTotal_lag14', 'PrecipTotal_lag15', 'PrecipTotal_lag16', 'PrecipTotal_lag17',\n",
    "           'PrecipTotal_lag18', 'PrecipTotal_lag19', 'PrecipTotal_lag20', 'PrecipTotal_lag21', 'PrecipTotal_lag22',\n",
    "           'PrecipTotal_lag23', 'PrecipTotal_lag24', 'PrecipTotal_lag25', 'PrecipTotal_lag26', 'PrecipTotal_lag27',\n",
    "           'PrecipTotal_lag28', 'DaylightMinutes_lag1', 'DaylightMinutes_lag2', 'DaylightMinutes_lag3',\n",
    "           'DaylightMinutes_lag4', 'DaylightMinutes_lag5', 'DaylightMinutes_lag6', 'DaylightMinutes_lag7',\n",
    "           'DaylightMinutes_lag8', 'DaylightMinutes_lag9', 'DaylightMinutes_lag10', 'DaylightMinutes_lag11',\n",
    "           'DaylightMinutes_lag12', 'DaylightMinutes_lag13', 'DaylightMinutes_lag14', 'DaylightMinutes_lag15',\n",
    "           'DaylightMinutes_lag16', 'DaylightMinutes_lag17', 'DaylightMinutes_lag18', 'DaylightMinutes_lag19',\n",
    "           'DaylightMinutes_lag20', 'DaylightMinutes_lag21', 'DaylightMinutes_lag22', 'DaylightMinutes_lag23',\n",
    "           'DaylightMinutes_lag24', 'DaylightMinutes_lag25', 'DaylightMinutes_lag26', 'DaylightMinutes_lag27',\n",
    "           'DaylightMinutes_lag28', 'RelHumidity_lag1', 'RelHumidity_lag2', 'RelHumidity_lag3', 'RelHumidity_lag4',\n",
    "           'RelHumidity_lag5', 'RelHumidity_lag6', 'RelHumidity_lag7', 'RelHumidity_lag8', 'RelHumidity_lag9',\n",
    "           'RelHumidity_lag10', 'RelHumidity_lag11', 'RelHumidity_lag12', 'RelHumidity_lag13', 'RelHumidity_lag14',\n",
    "           'RelHumidity_lag15', 'RelHumidity_lag16', 'RelHumidity_lag17', 'RelHumidity_lag18', 'RelHumidity_lag19',\n",
    "           'RelHumidity_lag20', 'RelHumidity_lag21', 'RelHumidity_lag22', 'RelHumidity_lag23', 'RelHumidity_lag24',\n",
    "           'RelHumidity_lag25', 'RelHumidity_lag26', 'RelHumidity_lag27', 'RelHumidity_lag28', 'Tavg_lag7_mean',\n",
    "           'Tavg_lag14_mean', 'Tavg_lag21_mean', 'Tavg_lag28_mean', 'Wind_AvgSpeed_lag7_mean', 'Wind_AvgSpeed_lag14_mean',\n",
    "           'Wind_AvgSpeed_lag21_mean', 'Wind_AvgSpeed_lag28_mean', 'PrecipTotal_lag7_mean', 'PrecipTotal_lag14_mean',\n",
    "           'PrecipTotal_lag21_mean', 'PrecipTotal_lag28_mean', 'DaylightMinutes_lag7_mean', 'DaylightMinutes_lag14_mean',\n",
    "           'DaylightMinutes_lag21_mean', 'DaylightMinutes_lag28_mean', 'RelHumidity_lag7_mean', 'RelHumidity_lag14_mean',\n",
    "           'RelHumidity_lag21_mean', 'RelHumidity_lag28_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479c068",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60b7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the data into feature matrix (X) and target vector (y)\n",
    "X = df.drop(columns='WnvPresent')\n",
    "y = df['WnvPresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d68b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y, train_size=0.7, stratify=y, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60560300",
   "metadata": {},
   "source": [
    "## Weight of Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bddbb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the bins for continuous variables\n",
    "def continuous_bins(X,y,max_bins=20,min_bins=2):\n",
    "    spearman_r = 0\n",
    "    n = max_bins\n",
    "    \n",
    "    #create the bins\n",
    "    while np.abs(spearman_r) < 1:\n",
    "        \n",
    "        #if below minimum bins manually create bins\n",
    "        if n < min_bins + 1:\n",
    "            bins = algos.quantile(X, np.linspace(0, 1, min_bins + 1))\n",
    "            if len(np.unique(bins)) == 2:\n",
    "                bins = np.insert(bins,0,1)\n",
    "                bins[1] = bins[1]-(bins[1]/2)\n",
    "            df_bins = pd.DataFrame({'X':X, 'y':y, \"Bin\": pd.cut(X, np.unique(bins),include_lowest=True)}) \\\n",
    "                .groupby('Bin')\n",
    "            break\n",
    "        \n",
    "        #create bins and check Spearman correlation\n",
    "        df_bins = pd.DataFrame({'X':X,'y':y,'Bin':pd.qcut(X,n,duplicates='drop')}).groupby('Bin')\n",
    "        spearman_r, p_val = stats.spearmanr(df_bins['X'].mean(),df_bins['y'].mean())\n",
    "        n -= 1\n",
    "\n",
    "    return df_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "736386ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the bins for discrete variables\n",
    "def discrete_bins(X,y):\n",
    "    return pd.DataFrame({'X':X, 'y':y}).groupby('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85398dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the weight of evidence table\n",
    "def get_woe_table(df_bins, is_continuous, feature_name):\n",
    "    \n",
    "    #for continuous data\n",
    "    if is_continuous:\n",
    "        min_value = df_bins['X'].min()\n",
    "        max_value = df_bins['X'].max()\n",
    "    \n",
    "    #for discrete data\n",
    "    else:\n",
    "        min_value = df_bins['y'].count().index\n",
    "        max_value = min_value\n",
    "\n",
    "        \n",
    "    count_total = df_bins['y'].count()\n",
    "    count_positive = df_bins['y'].sum()\n",
    "    count_negative = count_total - count_positive\n",
    "        \n",
    "    df_woe_table =  pd.DataFrame({\n",
    "        'Feature':feature_name,\n",
    "        'Minimum':min_value,\n",
    "        'Maximum':max_value,\n",
    "        'Total':count_total,\n",
    "        'TotalPositive':count_positive,\n",
    "        'TotalNegative':count_negative,\n",
    "        'PositiveRate': count_positive/count_total,\n",
    "        'NegativeRate': count_negative/count_total,\n",
    "        'ProportionOfPositives': count_positive / count_positive.sum(),\n",
    "        'ProportionOfNegatives': count_negative / count_negative.sum(),\n",
    "    })\n",
    "    \n",
    "    df_woe_table['WOE'] = np.log(df_woe_table['ProportionOfPositives']/df_woe_table['ProportionOfNegatives'])\n",
    "    df_woe_table['IV'] = (df_woe_table['ProportionOfPositives'] - df_woe_table['ProportionOfNegatives']) \\\n",
    "        * df_woe_table['WOE']\n",
    "    \n",
    "    #handle infinity values\n",
    "    df_woe_table = df_woe_table.replace([np.inf, -np.inf], 1)\n",
    "    \n",
    "    #drop any rows where there were no values in the bin\n",
    "    df_woe_table = df_woe_table.drop(index = df_woe_table[df_woe_table['Total'] == 0].index)\n",
    "    \n",
    "    return df_woe_table.reset_index(drop=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a861a30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "F:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'StnPressureTrapSprayDistance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mF:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'StnPressureTrapSprayDistance'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9f944e384361>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontinuous_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdf_bins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontinuous_bins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mwoe_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_woe_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_bins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\SpringBoardMain\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'StnPressureTrapSprayDistance'"
     ]
    }
   ],
   "source": [
    "#get WOE and IV values for each feature in X_train\n",
    "df_woe = None\n",
    "for column in categorical_columns:\n",
    "    \n",
    "    df_bins = discrete_bins(X_train[column],y_train)\n",
    "    woe_table = get_woe_table(df_bins, False, column)\n",
    "    \n",
    "    if df_woe is None:\n",
    "        df_woe = woe_table\n",
    "    else:\n",
    "        df_woe = pd.concat([df_woe,woe_table])\n",
    "        \n",
    "for column in continuous_columns:\n",
    "    \n",
    "    df_bins = continuous_bins(X_train[column],y_train)\n",
    "    woe_table = get_woe_table(df_bins, True, column)\n",
    "    \n",
    "    if df_woe is None:\n",
    "        df_woe = woe_table\n",
    "    else:\n",
    "        df_woe = pd.concat([df_woe,woe_table])\n",
    " \n",
    "\n",
    "df_woe = df_woe.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd1bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the max IV for each feature\n",
    "df_woe = df_woe.groupby('Feature')['IV'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceea031",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select features with IV >= 0.05 and IV <= 0.8\n",
    "features = df_woe[(df_woe['IV'] >= 0.05) & \\\n",
    "                  (df_woe['IV'] <= 0.8)].sort_values(by='IV', ascending=False)['Feature'].tolist()\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f63cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the feature lists\n",
    "categorical_columns = list(set(categorical_columns) & set(X_train.columns))\n",
    "continuous_columns = list(set(continuous_columns) & set(X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944637e9",
   "metadata": {},
   "source": [
    "## Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68518e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the encoder to the training data\n",
    "encoder = preprocessing.OneHotEncoder(sparse=False, drop='first')\n",
    "encoder.fit(X_train[categorical_columns])\n",
    "\n",
    "#Transform the training data\n",
    "encoded_columns = pd.DataFrame(encoder.transform(X_train[categorical_columns]))\n",
    "encoded_columns.columns = encoder.get_feature_names(categorical_columns)\n",
    "encoded_columns.index = X_train.index\n",
    "X_train =  pd.concat([X_train,encoded_columns], axis=1).drop(columns=categorical_columns)\n",
    "\n",
    "new_categorical_columns = encoded_columns.columns\n",
    "\n",
    "\n",
    "#Transform the test data\n",
    "encoded_columns = pd.DataFrame(encoder.transform(X_test[categorical_columns]))\n",
    "encoded_columns.columns = encoder.get_feature_names(categorical_columns)\n",
    "encoded_columns.index = X_test.index\n",
    "X_test = pd.concat([X_test,encoded_columns], axis=1).drop(columns=categorical_columns)\n",
    "\n",
    "\n",
    "categorical_columns = new_categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee846a",
   "metadata": {},
   "source": [
    "## Scale Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b253b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Numerical Data\n",
    "\n",
    "#Fit the scaler to the training data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train[continuous_columns])\n",
    "\n",
    "#Transform the training data\n",
    "scaled = pd.DataFrame(scaler.transform(X_train[continuous_columns]))\n",
    "scaled.columns = continuous_columns\n",
    "scaled.index = X_train.index\n",
    "X_train = pd.concat([scaled, X_train.drop(columns=continuous_columns)], axis=1)\n",
    "\n",
    "#Transform the test data\n",
    "scaled = pd.DataFrame(scaler.transform(X_test[continuous_columns]))\n",
    "scaled.columns = continuous_columns\n",
    "scaled.index = X_test.index\n",
    "X_test = pd.concat([scaled, X_test.drop(columns=continuous_columns)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe74158",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "X_train.describe().T.sort_values(by='max',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09592d06",
   "metadata": {},
   "source": [
    "## Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove features until VIF among all features is < 2\n",
    "while len(X_train.columns) > 0:\n",
    "\n",
    "    df_VIF = pd.DataFrame({'Feature':X_train.columns})\n",
    "    df_VIF['VIF'] = [variance_inflation_factor(X_train.values, i) for i in range(len(X_train.columns))]\n",
    "    \n",
    "    if df_VIF.loc[df_VIF['VIF'].idxmax()]['VIF'] < 2:\n",
    "        break\n",
    "        \n",
    "    X_train = X_train.drop(columns=df_VIF.loc[df_VIF['VIF'].idxmax()]['Feature'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6397e",
   "metadata": {},
   "source": [
    "## Save The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the training set\n",
    "datapath = '../data'\n",
    "save_file(X_train, 'X_train.csv', datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f63e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the training labels\n",
    "datapath = '../data'\n",
    "save_file(y_train, 'y_train.csv', datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the test set\n",
    "datapath = '../data'\n",
    "save_file(X_test, 'X_test.csv', datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6192ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the test labels\n",
    "datapath = '../data'\n",
    "save_file(y_test, 'y_test.csv', datapath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
